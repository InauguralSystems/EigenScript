# EigenScript Self-Hosting Compiler Driver
# Orchestrates: Lexer -> Parser -> Semantic -> Codegen
#
# Usage: eigensc source.eigs
# Output: LLVM IR to stdout (pipe to llvm-as)
#
# Compilation Pipeline:
# 1. Read source file
# 2. Tokenize (lexer.eigs)
# 3. Parse to AST (parser.eigs)
# 4. Semantic analysis (semantic.eigs)
# 5. Generate LLVM IR (codegen.eigs)
# 6. Output IR (link with runtime)

# Import compiler modules
import lexer
import parser
import semantic
import codegen

# ============================================================================
# Token Type Constants (needed for main)
# ============================================================================
TT_EOF is 99
TT_NUMBER is 30
TT_STRING is 31
TT_IDENTIFIER is 33

# ============================================================================
# Compilation State
# ============================================================================

# Source file content
source_code is ""
source_length is 0

# Compilation flags
verbose is 0
parse_only is 0
check_only is 0

# Error tracking
compile_errors is 0

# ============================================================================
# Phase 1: Lexical Analysis
# ============================================================================

define run_lexer as:
    if verbose = 1:
        print of "Phase 1: Lexical Analysis"

    # Set source for lexer
    result is lexer_set_source of source_code

    # Initialize and run lexer
    result is lexer_init_lexer of 0

    # Tokenize - this populates parser_token_* arrays
    token_count is 0

    loop while 1:
        tok is lexer_next_token of 0
        if tok = TT_EOF:
            break

        # Store token in parser arrays
        append of parser_token_types of tok
        append of parser_token_lines of lex_line
        append of parser_token_cols of lex_col

        # Store numeric value for numbers
        if tok = TT_NUMBER:
            append of parser_token_num_vals of lex_last_num_val
        else:
            append of parser_token_num_vals of 0

        # Store string index for identifiers/strings
        if tok = TT_IDENTIFIER:
            str_idx is lexer_get_identifier_index of 0
            append of parser_token_str_indices of str_idx
        else:
            if tok = TT_STRING:
                str_idx is lexer_get_string_index of 0
                append of parser_token_str_indices of str_idx
            else:
                append of parser_token_str_indices of 0

        token_count is token_count + 1

    # Add EOF token
    append of parser_token_types of TT_EOF
    append of parser_token_lines of lex_line
    append of parser_token_cols of lex_col
    append of parser_token_num_vals of 0
    append of parser_token_str_indices of 0
    parser_token_count is token_count + 1

    if verbose = 1:
        print of "  Tokens generated:"
        print of parser_token_count

    return parser_token_count

# ============================================================================
# Phase 2: Parsing
# ============================================================================

define run_parser as:
    if verbose = 1:
        print of "Phase 2: Parsing"

    # Parse tokens to AST
    print of 5001
    ast_root is parser_parse of 0
    print of 5002

    if parser_error = 1:
        print of "Parse error at line:"
        print of parser_error_line
        print of "column:"
        print of parser_error_col
        compile_errors is compile_errors + 1
        return 0

    if verbose = 1:
        print of "  AST nodes created:"
        print of ast_node_count

    return ast_root

# ============================================================================
# Phase 3: Semantic Analysis
# ============================================================================

define run_semantic of ast_root as:
    if verbose = 1:
        print of "Phase 3: Semantic Analysis"

    # Analyze AST
    error_count is semantic_analyze of ast_root

    if error_count > 0:
        print of "Semantic errors:"
        print of error_count
        result is semantic_print_errors of 0
        compile_errors is compile_errors + error_count
        return 0

    if verbose = 1:
        print of "  Symbols defined:"
        print of symbol_count

    return 1

# ============================================================================
# Phase 4: Code Generation
# ============================================================================

define run_codegen of ast_root as:
    if verbose = 1:
        print of "Phase 4: Code Generation"

    # Generate LLVM IR
    line_count is codegen_generate of ast_root

    if verbose = 1:
        print of "  IR lines generated:"
        print of line_count

    # Output IR
    result is codegen_print_ir of 0

    return line_count

# ============================================================================
# Main Compilation Entry Point
# ============================================================================

define compile of source as:
    # Store source
    source_code is source
    source_length is string_length of source

    if verbose = 1:
        print of "EigenScript Self-Hosting Compiler"
        print of "Source length:"
        print of source_length

    # Phase 1: Lexer
    token_count is run_lexer of 0
    if token_count = 0:
        print of "Lexer failed"
        return 0

    # Phase 2: Parser
    ast_root is run_parser of 0
    if ast_root = 0:
        if parser_error = 1:
            return 0

    if parse_only = 1:
        print of "Parse successful"
        return 1

    # Phase 3: Semantic Analysis
    sem_ok is run_semantic of ast_root
    if sem_ok = 0:
        return 0

    if check_only = 1:
        print of "Semantic check successful"
        return 1

    # Phase 4: Code Generation
    ir_lines is run_codegen of ast_root

    if compile_errors > 0:
        print of "Compilation failed with errors:"
        print of compile_errors
        return 0

    return 1

# ============================================================================
# Command Line Interface
# ============================================================================

# Parse command line arguments
define parse_args of args as:
    # For now, just check for flags
    # --verbose, --parse-only, --check-only

    i is 0
    arg_count is length of args

    loop while i < arg_count:
        arg is args[i]

        eq is string_equals of [arg, "--verbose"]
        if eq = 1:
            verbose is 1

        eq is string_equals of [arg, "--parse-only"]
        if eq = 1:
            parse_only is 1

        eq is string_equals of [arg, "--check-only"]
        if eq = 1:
            check_only is 1

        i is i + 1

    return 0

# ============================================================================
# File-Based Entry Point
# ============================================================================

# Compile a source file
define compile_file of filename as:
    print of "Reading file:"
    print of filename

    source is file_read of filename

    if source = 0:
        print of "Error: Could not read file"
        return 0

    print of "File read successfully"
    src_len is string_length of source
    print of "Source length:"
    print of src_len

    return compile of source

# ============================================================================
# Test Entry Point
# ============================================================================

# For testing without file I/O, compile a string directly
define compile_string of source as:
    return compile of source

# Test the compiler with a simple program
define test_compiler as:
    print of "Testing self-hosting compiler..."

    test_source is "x is 42\nprint of x"

    result is compile of test_source

    if result = 1:
        print of "Test passed!"
    else:
        print of "Test failed!"

    return result

# ============================================================================
# Initialization
# ============================================================================

# Initialize all modules
define init_compiler as:
    # Call module init functions to initialize their globals
    # These set up lexer state, parser token arrays, AST arrays, etc.
    # Note: Function names are mangled with module prefix (init_lexer -> lexer_init_lexer)
    result is lexer_init_lexer of 0
    result is parser_init_parser of 0
    result is semantic_init_semantic of 0
    result is codegen_init_codegen of 0

    # Reset compilation error counter
    compile_errors is 0

    return 0

# Signal that main module is loaded
print of 555

# Initialize
result is init_compiler of 0

# Check for command line arguments
argc is get_argc of 0

if argc > 1:
    # Compile the file specified on command line
    filename is get_arg of 1
    result is compile_file of filename
else:
    # No arguments - run the test
    result is test_compiler of 0
